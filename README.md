# ðŸ‘‹ Hi, I'm Bruni Liu

ðŸŽ“ Research-oriented undergraduate exploring the frontiers of **Multimodal Learning** and **Token Prediction**. My work lies at the intersection of AI architecture innovation and unified modality modeling.

---

## ðŸ”¬ Current Research Focus

- **PDEformer** â€” A next-token prediction model replacing self-attention with **PDE-based evolution** across multimodal token sequences. Inspired by [Emu3](https://arxiv.org/abs/2403.09364), it unifies visual and textual representations into a joint prediction space.
- **Emu3 Framework** â€” Studying the potential of **next-token prediction as a universal interface** for vision, text, and more. Exploring its extensibility to image-text retrieval and cross-modal indexing.
- **CLIP + GPT-2 Captioning** â€” A lightweight system built during **PKU Summer School 2025**, aligning CLIP embeddings with GPT-2 to generate captions. [View project](https://github.com/Bruni-coder/multimodal-captioning-via-clip-gpt2)

---

## ðŸ§  Research Interests

- Multimodal Retrieval & Representation Learning
- Attention-free Architectures
- Federated Learning & Privacy-preserving AI
- PyTorch Geometric & Graph-based Modeling

---

## ðŸŒ± About Me

- Passionate about building algorithms that generalize across modalities
- Always open to collaboration and academic discussion â€” feel free to reach out!

---

ðŸ“« **Contact**: You can reach me via GitHub issues or connect via email (available upon request).

ðŸ§­ *"Step by step, toward something beautiful and true."*
